{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5fsoM6_4COs"
   },
   "source": [
    "# Task 1: Custom Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zu6uwHw_5VF6"
   },
   "source": [
    "### I. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tBmHW5ly36MS"
   },
   "outputs": [],
   "source": [
    "# !pip install llmlingua\n",
    "# !pip install openai==0.28\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install scikit-learn\n",
    "# !pip install tensorboard\n",
    "\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_P4bGVFz5pJy"
   },
   "source": [
    "### II. Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOkmD_90Pszy"
   },
   "source": [
    "* Format data to a list of dict (idx, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCPIdDEB468s",
    "outputId": "af9659fd-a605-41d9-8a95-d14eedd47dfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "# Fig 12 example idx=3715\n",
    "data = []\n",
    "for idx, instance in enumerate(ds):\n",
    "    if idx==500: break\n",
    "    temp = {}\n",
    "    temp[\"idx\"] = idx\n",
    "    temp[\"prompt\"] = \"Question: \"+instance[\"question\"]+instance[\"answer\"]\n",
    "    #temp[\"summary\"] = instance[\"summary\"]\n",
    "    data.append(temp)\n",
    "    os.makedirs(\"../../../results/gsm8k/origin/\", exist_ok=True)\n",
    "    json.dump(data, open(\"../../../results/gsm8k/origin/gsm8k_train_formated.json\", \"w\"),\n",
    "    indent=4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYbxylHSDgwR"
   },
   "source": [
    "* instruct GPT-4 to compress the orignial context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S01y1H1n__gn",
    "outputId": "5d440ae7-2600-484c-858f-b461ea2a4ba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 500\n",
      "You are an excellent linguist and very good at compressing passages into short expressions by removing unimportant words, while retaining as much information as possible.\n",
      "Compress some text to short expressions, and such that you (GPT-4) can reconstruct it as close as possible to the original. Unlike the usual text compression, I need you to comply with the 5 conditions below: 1. You can ONLY remove unimportant words. 2. Do not change the order of words. 3. Do not change the original words, e.g. 'asking'->'ask' is NOT OK, 'current'->'now' is NOT OK. 4. Do not use abbreviations or emojis, e.g. 'without'->'w/o' is NOT OK, 'as soon as possible'->'ASAP' is NOT OK. 5. Do not add new words or symbols, this is very important. For example, 'dedicate 3 hours to each chapter'->'3 hours/chapter' is NOT OK because you add new token '/', just compress it into '3 hours each chapter'. '30 eggs plus 20 eggs equals 50 eggs'->'30+20=50' is also NOT OK becuase you add new symbols + and =, just compress it into '30 plus 20 equals 50'. \n",
      "Compress the origin aggressively by removing words only. Compress the origin as short as you can, while retaining as much information as possible. \n",
      "If you understand, please compress the following text: \n",
      "{text_to_compress}\n",
      "The compressed text is: \n",
      "  0% 0/500 [00:00<?, ?it/s]0-th sample is processed\n",
      "1-th sample is processed\n",
      "2-th sample is processed\n",
      "3-th sample is processed\n",
      "4-th sample is processed\n",
      "5-th sample is processed\n",
      "6-th sample is processed\n",
      "7-th sample is processed\n",
      "8-th sample is processed\n",
      "9-th sample is processed\n",
      "10-th sample is processed\n",
      "11-th sample is processed\n",
      "12-th sample is processed\n",
      "13-th sample is processed\n",
      "14-th sample is processed\n",
      "15-th sample is processed\n",
      "16-th sample is processed\n",
      "17-th sample is processed\n",
      "18-th sample is processed\n",
      "19-th sample is processed\n",
      "20-th sample is processed\n",
      "21-th sample is processed\n",
      "22-th sample is processed\n",
      "23-th sample is processed\n",
      "24-th sample is processed\n",
      "25-th sample is processed\n",
      "26-th sample is processed\n",
      "27-th sample is processed\n",
      "28-th sample is processed\n",
      "29-th sample is processed\n",
      "30-th sample is processed\n",
      "31-th sample is processed\n",
      "32-th sample is processed\n",
      "33-th sample is processed\n",
      "34-th sample is processed\n",
      "35-th sample is processed\n",
      "36-th sample is processed\n",
      "37-th sample is processed\n",
      "38-th sample is processed\n",
      "39-th sample is processed\n",
      "40-th sample is processed\n",
      "41-th sample is processed\n",
      "42-th sample is processed\n",
      "43-th sample is processed\n",
      "44-th sample is processed\n",
      "45-th sample is processed\n",
      "46-th sample is processed\n",
      "47-th sample is processed\n",
      "48-th sample is processed\n",
      "49-th sample is processed\n",
      "50-th sample is processed\n",
      "51-th sample is processed\n",
      "52-th sample is processed\n",
      "53-th sample is processed\n",
      "54-th sample is processed\n",
      "55-th sample is processed\n",
      "56-th sample is processed\n",
      "57-th sample is processed\n",
      "58-th sample is processed\n",
      "59-th sample is processed\n",
      "60-th sample is processed\n",
      "61-th sample is processed\n",
      "62-th sample is processed\n",
      "63-th sample is processed\n",
      "64-th sample is processed\n",
      "65-th sample is processed\n",
      "66-th sample is processed\n",
      "67-th sample is processed\n",
      "68-th sample is processed\n",
      "69-th sample is processed\n",
      "70-th sample is processed\n",
      "71-th sample is processed\n",
      "72-th sample is processed\n",
      "73-th sample is processed\n",
      "74-th sample is processed\n",
      "75-th sample is processed\n",
      "76-th sample is processed\n",
      "77-th sample is processed\n",
      "78-th sample is processed\n",
      "79-th sample is processed\n",
      "80-th sample is processed\n",
      "81-th sample is processed\n",
      "82-th sample is processed\n",
      "83-th sample is processed\n",
      "84-th sample is processed\n",
      "85-th sample is processed\n",
      "86-th sample is processed\n",
      "87-th sample is processed\n",
      "88-th sample is processed\n",
      "89-th sample is processed\n",
      "90-th sample is processed\n",
      "91-th sample is processed\n",
      "92-th sample is processed\n",
      "93-th sample is processed\n",
      "94-th sample is processed\n",
      "95-th sample is processed\n",
      "96-th sample is processed\n",
      "97-th sample is processed\n",
      "98-th sample is processed\n",
      "99-th sample is processed\n",
      "100-th sample is processed\n",
      "101-th sample is processed\n",
      "102-th sample is processed\n",
      "103-th sample is processed\n",
      "104-th sample is processed\n",
      "105-th sample is processed\n",
      "106-th sample is processed\n",
      "107-th sample is processed\n",
      "108-th sample is processed\n",
      "109-th sample is processed\n",
      "110-th sample is processed\n",
      "111-th sample is processed\n",
      "112-th sample is processed\n",
      "113-th sample is processed\n",
      "114-th sample is processed\n",
      "115-th sample is processed\n",
      "116-th sample is processed\n",
      "117-th sample is processed\n",
      "118-th sample is processed\n",
      "119-th sample is processed\n",
      "120-th sample is processed\n",
      "121-th sample is processed\n",
      "122-th sample is processed\n",
      "123-th sample is processed\n",
      "124-th sample is processed\n",
      "125-th sample is processed\n",
      "126-th sample is processed\n",
      "127-th sample is processed\n",
      "128-th sample is processed\n",
      "129-th sample is processed\n",
      "130-th sample is processed\n",
      "131-th sample is processed\n",
      "132-th sample is processed\n",
      "133-th sample is processed\n",
      "134-th sample is processed\n",
      "135-th sample is processed\n",
      "136-th sample is processed\n",
      "137-th sample is processed\n",
      "138-th sample is processed\n",
      "139-th sample is processed\n",
      "140-th sample is processed\n",
      "141-th sample is processed\n",
      "142-th sample is processed\n",
      "143-th sample is processed\n",
      "144-th sample is processed\n",
      "145-th sample is processed\n",
      "146-th sample is processed\n",
      "147-th sample is processed\n",
      "148-th sample is processed\n",
      "149-th sample is processed\n",
      "150-th sample is processed\n",
      "151-th sample is processed\n",
      "152-th sample is processed\n",
      "153-th sample is processed\n",
      "154-th sample is processed\n",
      "155-th sample is processed\n",
      "156-th sample is processed\n",
      "157-th sample is processed\n",
      "158-th sample is processed\n",
      "159-th sample is processed\n",
      "160-th sample is processed\n",
      "161-th sample is processed\n",
      "162-th sample is processed\n",
      "163-th sample is processed\n",
      "164-th sample is processed\n",
      "165-th sample is processed\n",
      "166-th sample is processed\n",
      "167-th sample is processed\n",
      "168-th sample is processed\n",
      "169-th sample is processed\n",
      "170-th sample is processed\n",
      "171-th sample is processed\n",
      "172-th sample is processed\n",
      "173-th sample is processed\n",
      "174-th sample is processed\n",
      "175-th sample is processed\n",
      "176-th sample is processed\n",
      "177-th sample is processed\n",
      "178-th sample is processed\n",
      "179-th sample is processed\n",
      "180-th sample is processed\n",
      "181-th sample is processed\n",
      "182-th sample is processed\n",
      "183-th sample is processed\n",
      "184-th sample is processed\n",
      "185-th sample is processed\n",
      "186-th sample is processed\n",
      "187-th sample is processed\n",
      "188-th sample is processed\n",
      "189-th sample is processed\n",
      "190-th sample is processed\n",
      "191-th sample is processed\n",
      "192-th sample is processed\n",
      "193-th sample is processed\n",
      "194-th sample is processed\n",
      "195-th sample is processed\n",
      "196-th sample is processed\n",
      "197-th sample is processed\n",
      "198-th sample is processed\n",
      "199-th sample is processed\n",
      "200-th sample is processed\n",
      "201-th sample is processed\n",
      "202-th sample is processed\n",
      "203-th sample is processed\n",
      "204-th sample is processed\n",
      "205-th sample is processed\n",
      "206-th sample is processed\n",
      "207-th sample is processed\n",
      "208-th sample is processed\n",
      "209-th sample is processed\n",
      "210-th sample is processed\n",
      "211-th sample is processed\n",
      "212-th sample is processed\n",
      "213-th sample is processed\n",
      "214-th sample is processed\n",
      "215-th sample is processed\n",
      "216-th sample is processed\n",
      "217-th sample is processed\n",
      "218-th sample is processed\n",
      "219-th sample is processed\n",
      "220-th sample is processed\n",
      "221-th sample is processed\n",
      "222-th sample is processed\n",
      "223-th sample is processed\n",
      "224-th sample is processed\n",
      "225-th sample is processed\n",
      "226-th sample is processed\n",
      "227-th sample is processed\n",
      "228-th sample is processed\n",
      "229-th sample is processed\n",
      "230-th sample is processed\n",
      "231-th sample is processed\n",
      "232-th sample is processed\n",
      "233-th sample is processed\n",
      "234-th sample is processed\n",
      "235-th sample is processed\n",
      "236-th sample is processed\n",
      "237-th sample is processed\n",
      "238-th sample is processed\n",
      "239-th sample is processed\n",
      "240-th sample is processed\n",
      "241-th sample is processed\n",
      "242-th sample is processed\n",
      "243-th sample is processed\n",
      "244-th sample is processed\n",
      "245-th sample is processed\n",
      "246-th sample is processed\n",
      "247-th sample is processed\n",
      "248-th sample is processed\n",
      "249-th sample is processed\n",
      "250-th sample is processed\n",
      "251-th sample is processed\n",
      "252-th sample is processed\n",
      "253-th sample is processed\n",
      "254-th sample is processed\n",
      "255-th sample is processed\n",
      "256-th sample is processed\n",
      "257-th sample is processed\n",
      "258-th sample is processed\n",
      "259-th sample is processed\n",
      "260-th sample is processed\n",
      "261-th sample is processed\n",
      "262-th sample is processed\n",
      "263-th sample is processed\n",
      "264-th sample is processed\n",
      "265-th sample is processed\n",
      "266-th sample is processed\n",
      "267-th sample is processed\n",
      "268-th sample is processed\n",
      "269-th sample is processed\n",
      "270-th sample is processed\n",
      "271-th sample is processed\n",
      "272-th sample is processed\n",
      "273-th sample is processed\n",
      "274-th sample is processed\n",
      "275-th sample is processed\n",
      "276-th sample is processed\n",
      "277-th sample is processed\n",
      "278-th sample is processed\n",
      "279-th sample is processed\n",
      "280-th sample is processed\n",
      "281-th sample is processed\n",
      "282-th sample is processed\n",
      "283-th sample is processed\n",
      "284-th sample is processed\n",
      "285-th sample is processed\n",
      "286-th sample is processed\n",
      "287-th sample is processed\n",
      "288-th sample is processed\n",
      "289-th sample is processed\n",
      "290-th sample is processed\n",
      "291-th sample is processed\n",
      "292-th sample is processed\n",
      "293-th sample is processed\n",
      "294-th sample is processed\n",
      "295-th sample is processed\n",
      "296-th sample is processed\n",
      "297-th sample is processed\n",
      "298-th sample is processed\n",
      "299-th sample is processed\n",
      "300-th sample is processed\n",
      "301-th sample is processed\n",
      "302-th sample is processed\n",
      "303-th sample is processed\n",
      "304-th sample is processed\n",
      "305-th sample is processed\n",
      "306-th sample is processed\n",
      "307-th sample is processed\n",
      "308-th sample is processed\n",
      "309-th sample is processed\n",
      "310-th sample is processed\n",
      "311-th sample is processed\n",
      "312-th sample is processed\n",
      "313-th sample is processed\n",
      "314-th sample is processed\n",
      "315-th sample is processed\n",
      "316-th sample is processed\n",
      "317-th sample is processed\n",
      "318-th sample is processed\n",
      "319-th sample is processed\n",
      "320-th sample is processed\n",
      "321-th sample is processed\n",
      "322-th sample is processed\n",
      "323-th sample is processed\n",
      "324-th sample is processed\n",
      "325-th sample is processed\n",
      "326-th sample is processed\n",
      "327-th sample is processed\n",
      "328-th sample is processed\n",
      "329-th sample is processed\n",
      "330-th sample is processed\n",
      "331-th sample is processed\n",
      "332-th sample is processed\n",
      "333-th sample is processed\n",
      "334-th sample is processed\n",
      "335-th sample is processed\n",
      "336-th sample is processed\n",
      "337-th sample is processed\n",
      "338-th sample is processed\n",
      "339-th sample is processed\n",
      "340-th sample is processed\n",
      "341-th sample is processed\n",
      "342-th sample is processed\n",
      "343-th sample is processed\n",
      "344-th sample is processed\n",
      "345-th sample is processed\n",
      "346-th sample is processed\n",
      "347-th sample is processed\n",
      "348-th sample is processed\n",
      "349-th sample is processed\n",
      "350-th sample is processed\n",
      "351-th sample is processed\n",
      "352-th sample is processed\n",
      "353-th sample is processed\n",
      "354-th sample is processed\n",
      "355-th sample is processed\n",
      "356-th sample is processed\n",
      "357-th sample is processed\n",
      "358-th sample is processed\n",
      "359-th sample is processed\n",
      "360-th sample is processed\n",
      "361-th sample is processed\n",
      "362-th sample is processed\n",
      "363-th sample is processed\n",
      "364-th sample is processed\n",
      "365-th sample is processed\n",
      "366-th sample is processed\n",
      "367-th sample is processed\n",
      "368-th sample is processed\n",
      "369-th sample is processed\n",
      "370-th sample is processed\n",
      "371-th sample is processed\n",
      "372-th sample is processed\n",
      "373-th sample is processed\n",
      "374-th sample is processed\n",
      "num chunk: 1\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      " 75% 376/500 [01:05<00:21,  5.75it/s]num chunk: 1\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      " 75% 377/500 [02:13<00:52,  2.33it/s]num chunk: 1\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      " 76% 378/500 [06:24<03:37,  1.78s/it]num chunk: 1\n",
      " 76% 379/500 [06:30<03:39,  1.81s/it]num chunk: 1\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      " 76% 380/500 [07:36<05:00,  2.50s/it]num chunk: 1\n",
      " 76% 381/500 [07:39<04:57,  2.50s/it]num chunk: 1\n",
      " 76% 382/500 [07:41<04:55,  2.50s/it]num chunk: 1\n",
      " 77% 383/500 [07:44<04:53,  2.51s/it]num chunk: 1\n",
      " 77% 384/500 [07:46<04:51,  2.51s/it]num chunk: 1\n",
      " 77% 385/500 [07:50<04:56,  2.58s/it]num chunk: 1\n",
      " 77% 386/500 [07:55<05:12,  2.74s/it]num chunk: 1\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      " 77% 387/500 [11:05<38:06, 20.23s/it]num chunk: 1\n",
      "error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      " 78% 388/500 [12:12<48:05, 25.76s/it]num chunk: 1\n",
      " 78% 389/500 [12:15<41:40, 22.53s/it]num chunk: 1\n",
      " 78% 390/500 [12:20<35:32, 19.39s/it]num chunk: 1\n",
      " 78% 391/500 [12:23<29:26, 16.21s/it]num chunk: 1\n",
      " 78% 392/500 [12:27<24:30, 13.61s/it]num chunk: 1\n",
      " 79% 393/500 [12:30<19:44, 11.07s/it]num chunk: 1\n",
      " 79% 394/500 [12:34<16:15,  9.21s/it]num chunk: 1\n",
      " 79% 395/500 [12:39<14:20,  8.20s/it]num chunk: 1\n",
      " 79% 396/500 [12:46<13:47,  7.95s/it]num chunk: 1\n",
      " 79% 397/500 [12:50<11:42,  6.82s/it]num chunk: 1\n",
      " 80% 398/500 [12:54<10:13,  6.02s/it]num chunk: 1\n",
      " 80% 399/500 [12:57<08:25,  5.00s/it]num chunk: 1\n",
      " 80% 400/500 [13:04<09:26,  5.66s/it]num chunk: 1\n",
      " 80% 401/500 [13:10<09:26,  5.73s/it]num chunk: 1\n",
      " 80% 402/500 [13:13<07:50,  4.80s/it]num chunk: 1\n",
      " 81% 403/500 [13:17<07:26,  4.61s/it]num chunk: 1\n",
      " 81% 404/500 [13:21<07:21,  4.60s/it]num chunk: 1\n",
      " 81% 405/500 [13:28<08:25,  5.32s/it]num chunk: 1\n",
      " 81% 406/500 [13:33<07:56,  5.07s/it]num chunk: 1\n",
      " 81% 407/500 [13:37<07:30,  4.84s/it]num chunk: 1\n",
      " 82% 408/500 [13:41<06:44,  4.40s/it]num chunk: 1\n",
      " 82% 409/500 [13:44<06:06,  4.02s/it]num chunk: 1\n",
      " 82% 410/500 [13:50<07:01,  4.69s/it]num chunk: 1\n",
      " 82% 411/500 [13:53<06:03,  4.08s/it]num chunk: 1\n",
      " 82% 412/500 [13:55<05:21,  3.65s/it]num chunk: 1\n",
      " 83% 413/500 [13:59<05:18,  3.66s/it]num chunk: 1\n",
      " 83% 414/500 [14:03<05:25,  3.79s/it]num chunk: 1\n",
      " 83% 415/500 [14:08<05:44,  4.05s/it]num chunk: 1\n",
      " 83% 416/500 [14:12<05:48,  4.14s/it]num chunk: 1\n",
      " 83% 417/500 [14:15<05:10,  3.74s/it]num chunk: 1\n",
      " 84% 418/500 [14:17<04:35,  3.36s/it]num chunk: 1\n",
      " 84% 419/500 [14:20<04:04,  3.02s/it]num chunk: 1\n",
      " 84% 420/500 [14:22<03:50,  2.88s/it]num chunk: 1\n",
      " 84% 421/500 [14:25<03:42,  2.82s/it]num chunk: 1\n",
      " 84% 422/500 [14:28<04:00,  3.08s/it]num chunk: 1\n",
      " 85% 423/500 [14:34<04:48,  3.74s/it]num chunk: 1\n",
      " 85% 424/500 [14:36<04:18,  3.41s/it]num chunk: 1\n",
      " 85% 425/500 [14:41<04:40,  3.74s/it]num chunk: 1\n",
      " 85% 426/500 [14:43<04:10,  3.38s/it]num chunk: 1\n",
      " 85% 427/500 [14:46<03:41,  3.04s/it]num chunk: 1\n",
      " 86% 428/500 [14:51<04:17,  3.58s/it]num chunk: 1\n",
      " 86% 429/500 [14:54<04:05,  3.46s/it]num chunk: 1\n",
      " 86% 430/500 [14:58<04:12,  3.60s/it]num chunk: 1\n",
      " 86% 431/500 [15:01<03:55,  3.41s/it]num chunk: 1\n",
      " 86% 432/500 [15:04<03:49,  3.37s/it]num chunk: 1\n",
      " 87% 433/500 [15:08<04:03,  3.64s/it]num chunk: 1\n",
      " 87% 434/500 [15:12<04:00,  3.64s/it]num chunk: 1\n",
      " 87% 435/500 [15:14<03:30,  3.24s/it]num chunk: 1\n",
      " 87% 436/500 [15:17<03:25,  3.21s/it]num chunk: 1\n",
      " 87% 437/500 [15:21<03:31,  3.36s/it]num chunk: 1\n",
      " 88% 438/500 [15:26<04:07,  3.99s/it]num chunk: 1\n",
      " 88% 439/500 [15:30<03:46,  3.72s/it]num chunk: 1\n",
      " 88% 440/500 [15:35<04:18,  4.30s/it]num chunk: 1\n",
      " 88% 441/500 [15:38<03:50,  3.90s/it]num chunk: 1\n",
      " 88% 442/500 [15:43<04:09,  4.30s/it]num chunk: 1\n",
      " 89% 443/500 [15:49<04:31,  4.76s/it]num chunk: 1\n",
      " 89% 444/500 [15:51<03:44,  4.00s/it]num chunk: 1\n",
      " 89% 445/500 [15:59<04:31,  4.93s/it]num chunk: 1\n",
      " 89% 446/500 [16:03<04:14,  4.71s/it]num chunk: 1\n",
      " 89% 447/500 [16:05<03:29,  3.96s/it]num chunk: 1\n",
      " 90% 448/500 [16:08<03:09,  3.65s/it]num chunk: 1\n",
      " 90% 449/500 [16:11<02:56,  3.46s/it]num chunk: 1\n",
      " 90% 450/500 [16:13<02:39,  3.18s/it]num chunk: 1\n",
      " 90% 451/500 [16:17<02:44,  3.37s/it]num chunk: 1\n",
      " 90% 452/500 [16:20<02:28,  3.09s/it]num chunk: 1\n",
      " 91% 453/500 [16:21<02:05,  2.66s/it]num chunk: 1\n",
      " 91% 454/500 [16:24<02:02,  2.66s/it]num chunk: 1\n",
      " 91% 455/500 [16:27<01:59,  2.66s/it]num chunk: 1\n",
      " 91% 456/500 [16:31<02:13,  3.04s/it]num chunk: 1\n",
      " 91% 457/500 [16:33<02:01,  2.82s/it]num chunk: 1\n",
      " 92% 458/500 [16:38<02:25,  3.47s/it]num chunk: 1\n",
      " 92% 459/500 [16:42<02:35,  3.80s/it]num chunk: 1\n",
      " 92% 460/500 [16:46<02:26,  3.67s/it]num chunk: 1\n",
      " 92% 461/500 [16:50<02:30,  3.86s/it]num chunk: 1\n",
      " 92% 462/500 [16:56<02:46,  4.39s/it]num chunk: 1\n",
      " 93% 463/500 [16:59<02:30,  4.06s/it]num chunk: 1\n",
      " 93% 464/500 [17:04<02:40,  4.47s/it]num chunk: 1\n",
      " 93% 465/500 [17:08<02:22,  4.06s/it]num chunk: 1\n",
      " 93% 466/500 [17:11<02:15,  3.98s/it]num chunk: 1\n",
      " 93% 467/500 [17:16<02:20,  4.25s/it]num chunk: 1\n",
      " 94% 468/500 [17:20<02:12,  4.13s/it]num chunk: 1\n",
      " 94% 469/500 [17:24<02:05,  4.06s/it]num chunk: 1\n",
      " 94% 470/500 [17:29<02:08,  4.27s/it]num chunk: 1\n",
      " 94% 471/500 [17:32<01:59,  4.11s/it]num chunk: 1\n",
      " 94% 472/500 [17:37<01:54,  4.10s/it]num chunk: 1\n",
      " 95% 473/500 [17:39<01:35,  3.54s/it]num chunk: 1\n",
      " 95% 474/500 [17:43<01:34,  3.65s/it]num chunk: 1\n",
      " 95% 475/500 [17:47<01:36,  3.85s/it]num chunk: 1\n",
      " 95% 476/500 [17:49<01:18,  3.27s/it]num chunk: 1\n",
      " 95% 477/500 [17:52<01:12,  3.17s/it]num chunk: 1\n",
      " 96% 478/500 [17:56<01:13,  3.32s/it]num chunk: 1\n",
      " 96% 479/500 [17:59<01:12,  3.47s/it]num chunk: 1\n",
      " 96% 480/500 [18:03<01:10,  3.53s/it]num chunk: 1\n",
      " 96% 481/500 [18:07<01:10,  3.72s/it]num chunk: 1\n",
      " 96% 482/500 [18:10<01:04,  3.58s/it]num chunk: 1\n",
      " 97% 483/500 [18:15<01:04,  3.77s/it]num chunk: 1\n",
      " 97% 484/500 [18:18<00:59,  3.72s/it]num chunk: 1\n",
      " 97% 485/500 [18:21<00:51,  3.44s/it]num chunk: 1\n",
      " 97% 486/500 [18:24<00:45,  3.23s/it]num chunk: 1\n",
      " 97% 487/500 [18:30<00:54,  4.22s/it]num chunk: 1\n",
      " 98% 488/500 [18:35<00:51,  4.31s/it]num chunk: 1\n",
      " 98% 489/500 [18:38<00:43,  3.97s/it]num chunk: 1\n",
      " 98% 490/500 [18:42<00:38,  3.83s/it]num chunk: 1\n",
      " 98% 491/500 [18:45<00:32,  3.58s/it]num chunk: 1\n",
      " 98% 492/500 [18:48<00:28,  3.52s/it]num chunk: 1\n",
      " 99% 493/500 [18:51<00:24,  3.50s/it]num chunk: 1\n",
      " 99% 494/500 [18:54<00:20,  3.36s/it]num chunk: 1\n",
      " 99% 495/500 [18:58<00:16,  3.30s/it]num chunk: 1\n",
      " 99% 496/500 [19:02<00:14,  3.59s/it]num chunk: 1\n",
      " 99% 497/500 [19:05<00:10,  3.56s/it]num chunk: 1\n",
      "100% 498/500 [19:10<00:07,  3.81s/it]num chunk: 1\n",
      "100% 499/500 [19:14<00:03,  3.84s/it]num chunk: 1\n",
      "100% 500/500 [19:16<00:00,  2.31s/it]\n",
      "../../../results/gsm8k/origin/compression_gsm8k_train_formated.json 1154.6104955673218\n"
     ]
    }
   ],
   "source": [
    "#!wget -O compress.py https://github.com/microsoft/LLMLingua/blob/main/experiments/llmlingua2/data_collection/compress.py\n",
    "!python compress.py --load_origin_from ../../../results/gsm8k/origin/gsm8k_train_formated.json \\\n",
    " --chunk_size 512 \\\n",
    " --compressor gpt4 \\\n",
    " --model_name gpt-4 \\\n",
    " --save_path ../../../results/gsm8k/origin/compression_gsm8k_train_formated.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MG3iIDG4MnZX"
   },
   "source": [
    "* assign label and filter out poor compression samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jprgfNmEyFf",
    "outputId": "6e1479a3-5680-4246-abbc-d76d82bbb8f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106it [00:04, 26.55it/s]Question: John buys 10 packs of magic cards.  Each pack has 20 cards and 1/4 of those cards are uncommon.  How many uncommon cards did he get?Each pack has 20/4 = <<20/4=5>>5 uncommons\n",
      "So he got 10*5 = <<10*5=50>>50 uncommons\n",
      "#### 50\n",
      "--------------------------------------------------\n",
      "\"John buys 10 packs magic cards. Each pack 20 cards, 1/4 uncommon. How many uncommon cards get? Each pack 20/4 = 5 uncommons. So got 10*5 = 50 uncommons. 50.\"\n",
      "--------------------------------------------------\n",
      "John buy 10 pack magic card . each pack 20 card 1/4 uncommon . how many uncommon card pack 20/4 = uncommon so get 10 * 5 = uncommon 50\n",
      "--------------------------------------------------\n",
      "['question', ':', 'John', 'buy', '10', 'pack', 'of', 'magic', 'card', '.', ' ', 'each', 'pack', 'have', '20', 'card', 'and', '1/4', 'of', 'those', 'card', 'be', 'uncommon', '.', ' ', 'how', 'many', 'uncommon', 'card', 'do', 'he', 'get?each', 'pack', 'have', '20/4', '=', '<', '<', '20/4=5>>5', 'uncommon', '\\n', 'so', 'he', 'get', '10', '*', '5', '=', '<', '<', '10', '*', '5=50>>50', 'uncommon', '\\n', '#', '#', '#', '#', '50']\n",
      "--------------------------------------------------\n",
      "['\"', 'John', 'buy', '10', 'pack', 'magic', 'card', '.', 'each', 'pack', '20', 'card', '1/4', 'uncommon', '.', 'how', 'many', 'uncommon', 'card', 'get', '?', 'each', 'pack', '20/4', '=', '5', 'uncommon', '.', 'so', 'get', '10', '*', '5', '=', '50', 'uncommon', '.', '50', '.', '\"']\n",
      "--------------------------------------------------\n",
      "['John', 'buy', '10', 'pack', 'magic', 'card', '.', 'each', 'pack', '20', 'card', '1/4', 'uncommon', '.', 'how', 'many', 'uncommon', 'card', 'pack', '20/4', '=', 'uncommon', 'so', 'get', '10', '*', '5', '=', 'uncommon', '50']\n",
      "==================================================\n",
      "comp rate: 0.6666666666666666, variation_rate: 0.07499999999999996, alignment_gap: 0.1166666666666667\n",
      "131it [00:05, 27.37it/s]Question: James buys 5 packs of beef that are 4 pounds each.  The price of beef is $5.50 per pound.  How much did he pay?He bought 5*4=<<5*4=20>>20 pounds of beef\n",
      "So he paid 20*5.5=$<<20*5.5=110>>110\n",
      "#### 110\n",
      "--------------------------------------------------\n",
      "James buys 5 packs beef 4 pounds each. Price beef $5.50 per pound. How much pay? Bought 20 pounds beef. Paid $110. 110.\n",
      "--------------------------------------------------\n",
      "James buy 5 pack beef 4 pound each . price beef $ 5.50 per pound . how much buy pound beef pay 20 110\n",
      "--------------------------------------------------\n",
      "['question', ':', 'James', 'buy', '5', 'pack', 'of', 'beef', 'that', 'be', '4', 'pound', 'each', '.', ' ', 'the', 'price', 'of', 'beef', 'be', '$', '5.50', 'per', 'pound', '.', ' ', 'how', 'much', 'do', 'he', 'pay?He', 'buy', '5', '*', '4=<<5', '*', '4=20>>20', 'pound', 'of', 'beef', '\\n', 'so', 'he', 'pay', '20', '*', '5.5=$<<20', '*', '5.5=110>>110', '\\n', '#', '#', '#', '#', '110']\n",
      "--------------------------------------------------\n",
      "['James', 'buy', '5', 'pack', 'beef', '4', 'pound', 'each', '.', 'price', 'beef', '$', '5.50', 'per', 'pound', '.', 'how', 'much', 'pay', '?', 'buy', '20', 'pound', 'beef', '.', 'pay', '$', '110', '.', '110', '.']\n",
      "--------------------------------------------------\n",
      "['James', 'buy', '5', 'pack', 'beef', '4', 'pound', 'each', '.', 'price', 'beef', '$', '5.50', 'per', 'pound', '.', 'how', 'much', 'buy', 'pound', 'beef', 'pay', '20', '110']\n",
      "==================================================\n",
      "comp rate: 0.5636363636363636, variation_rate: 0.032258064516129004, alignment_gap: 0.10909090909090907\n",
      "228it [00:08, 25.02it/s]Question: A company has 200 employees.  60% of the employees drive to work.  Of the employees who don't drive to work, half take public transportation. How many more employees drive to work than take public transportation?Drive to work:200(.60)=<<200*.60=120>>120\n",
      "Don't Drive to work:200-120=<<200-120=80>>80\n",
      "Public Transportation:80(.50)=40 employees\n",
      "80-40=<<80-40=40>>40 employees\n",
      "#### 40\n",
      "--------------------------------------------------\n",
      "\"Company has 200 employees. 60% drive to work. Employees not driving, half take public transportation. How many more drive than take public transportation? Drive: 200(.60)=120. Don't Drive: 200-120=80. Public Transportation: 80(.50)=40. 80-40=40 employees. 40.\"\n",
      "--------------------------------------------------\n",
      ": company have 200 employee . 60 % drive to work . employee do not drive half take public transportation . how many more drive than take public not drive - public employee 80 - 40\n",
      "--------------------------------------------------\n",
      "['question', ':', 'a', 'company', 'have', '200', 'employee', '.', ' ', '60', '%', 'of', 'the', 'employee', 'drive', 'to', 'work', '.', ' ', 'of', 'the', 'employee', 'who', 'do', 'not', 'drive', 'to', 'work', 'half', 'take', 'public', 'transportation', '.', 'how', 'many', 'more', 'employee', 'drive', 'to', 'work', 'than', 'take', 'public', 'transportation?drive', 'to', 'work:200(.60)=<<200*.60=120>>120', '\\n', 'do', 'not', 'drive', 'to', 'work:200', '-', '120=<<200', '-', '120=80>>80', '\\n', 'public', 'transportation:80(.50)=40', 'employee', '\\n', '80', '-', '40=<<80', '-', '40=40>>40', 'employee', '\\n', '#', '#', '#', '#', '40']\n",
      "--------------------------------------------------\n",
      "['\"', 'company', 'have', '200', 'employee', '.', '60', '%', 'drive', 'to', 'work', '.', 'employee', 'not', 'drive', 'half', 'take', 'public', 'transportation', '.', 'how', 'many', 'more', 'drive', 'than', 'take', 'public', 'transportation', '?', 'drive', ':', '200(.60)=120', '.', 'do', 'not', 'drive', ':', '200', '-', '120=80', '.', 'Public', 'Transportation', ':', '80(.50)=40', '.', '80', '-', '40=40', 'employee', '.', '40', '.', '\"']\n",
      "--------------------------------------------------\n",
      "[':', 'company', 'have', '200', 'employee', '.', '60', '%', 'drive', 'to', 'work', '.', 'employee', 'do', 'not', 'drive', 'half', 'take', 'public', 'transportation', '.', 'how', 'many', 'more', 'drive', 'than', 'take', 'public', 'not', 'drive', '-', 'public', 'employee', '80', '-', '40']\n",
      "==================================================\n",
      "comp rate: 0.7397260273972602, variation_rate: 0.12962962962962965, alignment_gap: 0.15068493150684936\n",
      "323it [00:12, 26.58it/s]Question: Bob was creating a math test for an online platform.  He created 13 questions in the first hour.  Bob then doubled his rate for the second hour, and doubled his second hour rate for the third hour.  How many questions did Bob create in the three hours?First hour: <<13=13>>13\n",
      "Second hour:13(2)=26\n",
      "Third hour: 26(2)=52\n",
      "Total:13+26+52=<<13+26+52=91>>91 questions\n",
      "#### 91\n",
      "--------------------------------------------------\n",
      "Bob creating math test online platform. Created 13 questions first hour. Doubled rate second hour, doubled second hour rate third hour. How many questions three hours? First hour: 13. Second hour: 26. Third hour: 52. Total: 91 questions.\n",
      "--------------------------------------------------\n",
      ": Bob create math test online platform . create 13 question first hour . double rate second hour double second hour rate third hour . how many question three hour : Second third hour : 26 question 91\n",
      "--------------------------------------------------\n",
      "['question', ':', 'Bob', 'be', 'create', 'a', 'math', 'test', 'for', 'an', 'online', 'platform', '.', ' ', 'he', 'create', '13', 'question', 'in', 'the', 'first', 'hour', '.', ' ', 'Bob', 'then', 'double', 'his', 'rate', 'for', 'the', 'second', 'hour', 'and', 'double', 'his', 'second', 'hour', 'rate', 'for', 'the', 'third', 'hour', '.', ' ', 'how', 'many', 'question', 'do', 'Bob', 'create', 'in', 'the', 'three', 'hours?first', 'hour', ':', '<', '<', '13=13>>13', '\\n', 'Second', 'hour:13(2)=26', '\\n', 'third', 'hour', ':', '26(2)=52', '\\n', 'Total:13', '+', '26', '+', '52=<<13', '+', '26', '+', '52=91>>91', 'question', '\\n', '#', '#', '#', '#', '91']\n",
      "--------------------------------------------------\n",
      "['Bob', 'create', 'math', 'test', 'online', 'platform', '.', 'create', '13', 'question', 'first', 'hour', '.', 'double', 'rate', 'second', 'hour', 'double', 'second', 'hour', 'rate', 'third', 'hour', '.', 'how', 'many', 'question', 'three', 'hour', '?', 'first', 'hour', ':', '13', '.', 'second', 'hour', ':', '26', '.', 'third', 'hour', ':', '52', '.', 'total', ':', '91', 'question', '.']\n",
      "--------------------------------------------------\n",
      "[':', 'Bob', 'create', 'math', 'test', 'online', 'platform', '.', 'create', '13', 'question', 'first', 'hour', '.', 'double', 'rate', 'second', 'hour', 'double', 'second', 'hour', 'rate', 'third', 'hour', '.', 'how', 'many', 'question', 'three', 'hour', ':', 'Second', 'third', 'hour', ':', '26', 'question', '91']\n",
      "==================================================\n",
      "comp rate: 0.5882352941176471, variation_rate: 0.06000000000000005, alignment_gap: 0.10588235294117648\n",
      "347it [00:13, 25.38it/s]Question: A farmer has twice as many pigs as cows, and 4 more cows than goats.  If the farmer has 56 animals total, how many goats does he have?Let x be the number of goats\n",
      "Cows:4+x\n",
      "Pigs:2(4+x)=8+2x\n",
      "Total:x+4+x+8+2x=56\n",
      "4x+12=56\n",
      "4x=44\n",
      "x=<<11=11>>11 goats\n",
      "#### 11\n",
      "--------------------------------------------------\n",
      "Farmer twice pigs as cows, 4 more cows than goats. 56 animals total, how many goats? x goats. Cows:4+x. Pigs:2(4+x)=8+2x. Total:x+4+x+8+2x=56. 4x+12=56. 4x=44. x=11 goats. 11.\n",
      "--------------------------------------------------\n",
      "farmer twice pig as cow 4 more cow than goat . 56 animal total how many goat x goat Cows:4+x Pigs:2(4+x)=8 + 2x Total : x+4+x+8 + 2x=56 4x+12=56 4x=44 goat 11\n",
      "--------------------------------------------------\n",
      "['question', ':', 'a', 'farmer', 'have', 'twice', 'as', 'many', 'pig', 'as', 'cow', 'and', '4', 'more', 'cow', 'than', 'goat', '.', ' ', 'if', 'the', 'farmer', 'have', '56', 'animal', 'total', 'how', 'many', 'goat', 'do', 'he', 'have?let', 'x', 'be', 'the', 'number', 'of', 'goat', '\\n', 'Cows:4+x', '\\n', 'Pigs:2(4+x)=8', '+', '2x', '\\n', 'Total', ':', 'x+4+x+8', '+', '2x=56', '\\n', '4x+12=56', '\\n', '4x=44', '\\n', 'x=<<11=11>>11', 'goat', '\\n', '#', '#', '#', '#', '11']\n",
      "--------------------------------------------------\n",
      "['farmer', 'twice', 'pig', 'as', 'cow', '4', 'more', 'cow', 'than', 'goat', '.', '56', 'animal', 'total', 'how', 'many', 'goat', '?', 'x', 'goat', '.', 'Cows:4+x', '.', 'Pigs:2(4+x)=8', '+', '2x', '.', 'total', ':', 'x+4+x+8', '+', '2x=56', '.', '4x+12=56', '.', '4x=44', '.', 'x=11', 'goat', '.', '11', '.']\n",
      "--------------------------------------------------\n",
      "['farmer', 'twice', 'pig', 'as', 'cow', '4', 'more', 'cow', 'than', 'goat', '.', '56', 'animal', 'total', 'how', 'many', 'goat', 'x', 'goat', 'Cows:4+x', 'Pigs:2(4+x)=8', '+', '2x', 'Total', ':', 'x+4+x+8', '+', '2x=56', '4x+12=56', '4x=44', 'goat', '11']\n",
      "==================================================\n",
      "comp rate: 0.6666666666666666, variation_rate: 0.04761904761904767, alignment_gap: 0.12698412698412698\n",
      "500it [00:19, 26.13it/s]\n",
      "window size: 400, comp rate: 0.4755693744612764, hitting_rate: 0.45395719555402947, retrieval rate: 0.42343493913779184\n"
     ]
    }
   ],
   "source": [
    "#!wget -O label_word.py https://github.com/microsoft/LLMLingua/blob/main/experiments/llmlingua2/data_collection/label_word.py\n",
    "!python label_word.py --load_prompt_from ../../../results/gsm8k/origin/compression_gsm8k_train_formated.json \\\n",
    "--window_size 400 \\\n",
    "--save_path ../../../results/gsm8k/origin/annotation_gsm8k_train_formated.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YL-xmoARM0mD",
    "outputId": "b3de1b93-0ce7-49e4-9438-8afa3c0c7e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/filter.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res_pt = torch.load(args.load_path)\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#!wget -O filter.py https://github.com/microsoft/LLMLingua/blob/main/experiments/llmlingua2/data_collection/filter.py\n",
    "!python filter.py --load_path ../../../results/gsm8k/origin/annotation_gsm8k_train_formated.pt \\\n",
    "--save_path ../../../results/gsm8k/origin/annotation_kept_gsm8k_train_formated.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2Q4h8-xRxDV"
   },
   "source": [
    "### III. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mYlAzzGRoEy",
    "outputId": "0a18c420-0de5-4f24-e6d0-35bec21ce7c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-22 02:34:23.727415: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-22 02:34:23.745284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-22 02:34:23.766979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-22 02:34:23.773454: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 02:34:23.789015: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-22 02:34:24.883732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/content/train_roberta.py:168: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(args.data_path)\n",
      "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 149kB/s]\n",
      "config.json: 100% 616/616 [00:00<00:00, 4.58MB/s]\n",
      "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:02<00:00, 2.45MB/s]\n",
      "tokenizer.json: 100% 9.10M/9.10M [00:00<00:00, 10.5MB/s]\n",
      "model.safetensors: 100% 2.24G/2.24G [00:10<00:00, 207MB/s]\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "len taining set: 324, len validation set: 81\n",
      "{'ids': tensor([     0,   9655,    152,   1543,    831,    472,   6773,    138,  35006,\n",
      "           420,   4527,   1632,  38933,     19,      6,      5,   2412,  22113,\n",
      "           116,   4842,  38933,     19,    305,  57571,  38933,     19,    136,\n",
      "           201, 205811,  38933,     19,      6,      5,   3642,   5941,  35006,\n",
      "           420,   1221,   2412,    186,  19048,     47,   3249,     23,   3622,\n",
      "            32,  82419,   1221,    186,  19048,     47,   3249,    116,   1022,\n",
      "           138,   2203,   4426,   4426,    116,    661,    138,   1369,    910,\n",
      "         30813,    910,   4842,  35006,    420,      6,      5,   2412,   1221,\n",
      "           186,  19048,     47,   3249,    138,   1022,    305,   2203,   4426,\n",
      "         21670,    661,    305,   1369,   1819,  30813,   1819,  57571,  35006,\n",
      "           420,      6,      5,    136,   2412,   1221,    186,  19048,     47,\n",
      "          3249,    201,   1022,    138,   2203,   4426,   4426,    201,    661,\n",
      "           138,   1369,   1530,  30813,   1530, 205811,  35006,    420,      6,\n",
      "             5, 127298,     70,   3622,  35006,    420,   2412,    831,   3249,\n",
      "           186,    427,    997,    543,    997,    305,   2203,   4426,   4426,\n",
      "           427,    997,    543,    997,    305,   1369,   8659,  30813,   8659,\n",
      "             6,      5,    468,    468,    468,    468,   4039,      2,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1]), 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'targets': tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
      "<s>         0\n",
      "▁question   0\n",
      "▁:          0\n",
      "▁may        1\n",
      "▁can        0\n",
      "▁k          1\n",
      "nit         1\n",
      "▁3          1\n",
      "▁scar       0\n",
      "f           0\n",
      "▁use        0\n",
      "▁one        1\n",
      "▁yar        1\n",
      "n           1\n",
      "▁           1\n",
      ".           1\n",
      "▁she        0\n",
      "▁buy        1\n",
      "▁2          1\n",
      "▁red        1\n",
      "▁yar        0\n",
      "n           0\n",
      "▁6          1\n",
      "▁blue       1\n",
      "▁yar        0\n",
      "n           0\n",
      "▁and        0\n",
      "▁4          1\n",
      "▁yellow     1\n",
      "▁yar        1\n",
      "tensor(0.7636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 512, 2])\n",
      "  0% 0/10 [00:00<?, ?it/s]Training epoch: 1\n",
      "Training loss per 100 training steps: 0.7656740546226501\n",
      "Training loss epoch: 0.29905330005920294\n",
      "Training accuracy epoch: 0.6331217344021882\n",
      "Validation Loss: 0.18163596424791548\n",
      "Validation Accuracy: 0.732271588806383\n",
      " 10% 1/10 [00:46<06:56, 46.29s/it]Training epoch: 2\n",
      "Training loss per 100 training steps: 0.1813492476940155\n",
      "Training loss epoch: 0.1604810350320556\n",
      "Training accuracy epoch: 0.7671549852954286\n",
      "Validation Loss: 0.14313147796524894\n",
      "Validation Accuracy: 0.7959140245010339\n",
      " 20% 2/10 [01:32<06:10, 46.34s/it]Training epoch: 3\n",
      "Training loss per 100 training steps: 0.14354094862937927\n",
      "Training loss epoch: 0.13691900557640826\n",
      "Training accuracy epoch: 0.8053098519737063\n",
      "Validation Loss: 0.12948522551192176\n",
      "Validation Accuracy: 0.819225543990037\n",
      " 30% 3/10 [02:17<05:20, 45.84s/it]Training epoch: 4\n",
      "Training loss per 100 training steps: 0.13578805327415466\n",
      "Training loss epoch: 0.1266119678815206\n",
      "Training accuracy epoch: 0.8227333607695854\n",
      "Validation Loss: 0.12465941409269969\n",
      "Validation Accuracy: 0.8293207538867522\n",
      " 40% 4/10 [03:06<04:40, 46.83s/it]Training epoch: 5\n",
      "Training loss per 100 training steps: 0.12615209817886353\n",
      "Training loss epoch: 0.1170555359937928\n",
      "Training accuracy epoch: 0.8402505911861283\n",
      "Validation Loss: 0.12368364218208525\n",
      "Validation Accuracy: 0.836685336856905\n",
      " 50% 5/10 [03:50<03:48, 45.76s/it]Training epoch: 6\n",
      "Training loss per 100 training steps: 0.10173086076974869\n",
      "Training loss epoch: 0.10943687865228365\n",
      "Training accuracy epoch: 0.8555561573698176\n",
      "Validation Loss: 0.12499635418256123\n",
      "Validation Accuracy: 0.8347193439441938\n",
      " 60% 6/10 [04:23<02:46, 41.69s/it]Training epoch: 7\n",
      "Training loss per 100 training steps: 0.12005314975976944\n",
      "Training loss epoch: 0.1043356666059205\n",
      "Training accuracy epoch: 0.8648215049391855\n",
      "Validation Loss: 0.1296938748823272\n",
      "Validation Accuracy: 0.8361312990007176\n",
      " 70% 7/10 [04:57<01:57, 39.07s/it]Training epoch: 8\n",
      "Training loss per 100 training steps: 0.10670745372772217\n",
      "Training loss epoch: 0.0969484814188697\n",
      "Training accuracy epoch: 0.8756677228742852\n",
      "Validation Loss: 0.12826206369532478\n",
      "Validation Accuracy: 0.835356362847079\n",
      " 80% 8/10 [05:31<01:14, 37.41s/it]Training epoch: 9\n",
      "Training loss per 100 training steps: 0.10819456726312637\n",
      "Training loss epoch: 0.08929000162717068\n",
      "Training accuracy epoch: 0.8880752765181062\n",
      "Validation Loss: 0.14571991148922178\n",
      "Validation Accuracy: 0.8256628645967125\n",
      " 90% 9/10 [06:04<00:36, 36.15s/it]Training epoch: 10\n",
      "Training loss per 100 training steps: 0.08020316064357758\n",
      "Training loss epoch: 0.08583226958007524\n",
      "Training accuracy epoch: 0.8916320548948262\n",
      "Validation Loss: 0.13651246908638212\n",
      "Validation Accuracy: 0.8345592924379582\n",
      "100% 10/10 [06:38<00:00, 39.84s/it]\n"
     ]
    }
   ],
   "source": [
    "!python train_roberta.py --data_path ../../../results/gsm8k/origin/annotation_kept_gsm8k_train_formated.pt \\\n",
    "    --save_path ../../../results/models/xlm-roberta-large-gsm8k-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMddCzrARwWK"
   },
   "source": [
    "### IV. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u2ogIvf4Gq5-"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds_test = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")\n",
    "original_prompts = []\n",
    "for idx, instance in enumerate(ds_test):\n",
    "  original_prompts.append(\"Question: \"+instance['question']+instance['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "1a6d9af08f574adebcb243051de3989f",
      "d6ee8ab8532842e19bbab04922824e1c",
      "37eacec4dbe141668baf92071cba3ccf",
      "055d74565f914469ba00614676e368a3",
      "458e208df1794d7ea9820feef97c792e",
      "aa387eb7f3114c65bdf453feb68ba546",
      "4316dbb1ea1646eda58a55ce21d5c62d",
      "b71d48e94cb542b7b8a3ddedafb4694e",
      "902ac47bab3c4b79a1c5c9833ef0771f",
      "41717bab365d41738ddab51c970ff082",
      "47710d0ba8134383a49f8aa69876ec57",
      "c055317a0ffe41a59e3b3cb9740f1b26",
      "9e9f6963ccd74b04b1c340f38ad0085e",
      "15099efd84b8479c9b099eea8eb256ca",
      "441121bfc5d2456baef40918c569e3f4",
      "44124ff62a604f4f8f23f9e3821c4f7f",
      "80d09c012dca492195afd4160b8c2f2a",
      "adab1fd4ae9a4b3a9eaf926ded6acebb",
      "8f6e79ddd93c47f78c8a0c3276c1d8c9",
      "0e272568c997469e91a5af53712a94f6",
      "d1419f06bc834f548ba2363199c1b22a",
      "5dbabf2bf8f149f6b6a3f1591367ddae",
      "ef58dc5e3b8e46b588e97de224efb6bf",
      "a15cb98c9c7a4b40bc857dc7ad0825c3",
      "35849c87372044bda37cfd4a1b33ae87",
      "b75adac8b42948808db6be7f7f56ed4d",
      "3060fa8ab91b4f5ab3f1d7dc8003809e",
      "89611b19571f42aa961262a2f1dfaca3",
      "b92c6b101bb341c59a6d9ea1a96015f4",
      "f185f34678cf437785dafbbf6f85b190",
      "2b0754ec79f54d1f8220eee420187465",
      "99f6755ffba74f7198d0256644b72709",
      "7a0def99c95340c2b398989c77ea904f",
      "5b0a05e2a2504acead659b26cd0250df",
      "f58550f941954550b144b26c93ae9681",
      "a318b3606d1f408f9bbd4f99daf139a2",
      "69fde6cac95c4817bd81e5da0797c23c",
      "8a3ed035e21b4ab7bf79083f96a7828d",
      "5e48bb2300734ab79a9984a52d3a09ab",
      "7bfeed68d5244973a4f6e3b46896bee8",
      "80ce7bc5c8bd4bc4826755a13bb2c831",
      "7dea05b331dc40c9a12e18177eec94fe",
      "aef9cde2bf554d26a3ab281fd9fd1bc1",
      "cde386a8fe4942bcb63ea87653b5f604",
      "d534147c6a4943c2a9f40576d317dc5f",
      "ca3a9ab75e594f98be5770239fc6a333",
      "e35cc3c94e8f4db4b12b10b49389a49d",
      "2e0615a90da14107bdd9cab3afd165dd",
      "d1542c26406746e88104bb2d9ca64036",
      "4f629e730b9948f4ae04bee1f8821bc3",
      "713f5ec4830b4763839d823c1ffe764b",
      "1c2160b85ff345b9b6e52ca6c2081271",
      "e74d2db6b99746ef81a2b821d5b18d7c",
      "242a154053f04d66ba1cee04730f3bb8",
      "3f6f092096744723a243334d80bcd69c"
     ]
    },
    "id": "_8ElPntUv728",
    "outputId": "967b8b57-bb3c-4ee5-cef5-acddf8f6c361"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6d9af08f574adebcb243051de3989f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/752 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c055317a0ffe41a59e3b3cb9740f1b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef58dc5e3b8e46b588e97de224efb6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0a05e2a2504acead659b26cd0250df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d534147c6a4943c2a9f40576d317dc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llmlingua import PromptCompressor\n",
    "\n",
    "model_meetingbank=\"microsoft/llmlingua-2-xlm-roberta-large-meetingbank\"\n",
    "model_gsm8k = '../../../results/models/xlm-roberta-large-gsm8k-only'\n",
    "\n",
    "compressor_meetingbank = PromptCompressor(\n",
    "    model_name=model_meetingbank,\n",
    "    use_llmlingua2=True\n",
    ")\n",
    "\n",
    "compressor_gsm8k = PromptCompressor(\n",
    "    model_name=model_gsm8k,\n",
    "    use_llmlingua2=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "LCXhi03XVGQ7"
   },
   "outputs": [],
   "source": [
    "def compare(prompt):\n",
    "  results_meetingbank = compressor_meetingbank.compress_prompt_llmlingua2(\n",
    "      prompt,\n",
    "      rate=0.6,\n",
    "      force_tokens=['\\n', '.', '!', '?', ','],\n",
    "      chunk_end_tokens=['.', '\\n'],\n",
    "      return_word_label=True,\n",
    "      drop_consecutive=True\n",
    "  )\n",
    "  results_gsm8k = compressor_gsm8k.compress_prompt_llmlingua2(\n",
    "      prompt,\n",
    "      rate=0.6,\n",
    "      force_tokens=['\\n', '.', '!', '?', ','],\n",
    "      chunk_end_tokens=['.', '\\n'],\n",
    "      return_word_label=True,\n",
    "      drop_consecutive=True\n",
    "  )\n",
    "  return results_meetingbank['compressed_prompt'], results_gsm8k['compressed_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWtjJ1i6Vin-",
    "outputId": "c9d64fe6-46fa-41b3-81bf-0b8c383a8fd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prompt:\n",
      "Question: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
      "#### 18\n",
      "Compressed prompt before training\n",
      "Janet’s ducks lay 16 eggs day. eats three breakfast bakes muffins friends. sells remainder farmers' market $2 per fresh duck egg. dollars farmers' market?Janet sells 16 - 3 - 4 =-3-4=9>>9 duck eggs.\n",
      " makes 9 * 2 = $<9*2=18>>18 farmer’s market.\n",
      "\n",
      "Compressed prompt after training\n",
      "Janet’s ducks lay 16 eggs per day. eats three for breakfast morning bakes muffins friends day with four. sells remainder at farmers market daily for $2 per fresh duck egg. dollars market?Janet sells 16 3 4 duck eggs a day.\n",
      " makes 9 2 $ every farmer’s market.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = original_prompts[0]\n",
    "compressed_prompt_before, compressed_prompt_after = compare(prompt)\n",
    "\n",
    "print(\"Original prompt:\")\n",
    "print(prompt)\n",
    "\n",
    "print(\"Compressed prompt before training\")\n",
    "print(compressed_prompt_before)\n",
    "\n",
    "print(\"Compressed prompt after training\")\n",
    "print(compressed_prompt_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| keywords | before training | after tranining |\n",
    "|----------|----------|----------|\n",
    "| 16 eggs  | yes  | yes  |\n",
    "| three for breakfast | yes  | yes |\n",
    "| muffins with four | no  | yes  |\n",
    "| sells remainder for $2 | yes  | yes  |\n",
    "| 16-3-4=9 | yes  | no  |\n",
    "| 9*2=18 | yes  | no  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vI5_IrtCaF4g",
    "outputId": "87f1443a-5365-434e-ba03-a29bee54beda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prompt:\n",
      "Question: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?It takes 2/2=<<2/2=1>>1 bolt of white fiber\n",
      "So the total amount of fabric is 2+1=<<2+1=3>>3 bolts of fabric\n",
      "#### 3\n",
      "Compressed prompt before training\n",
      "robe takes 2 bolts blue half white fiber. How many bolts total takes 2/2=<2/2=1>>1 bolt white fiber\n",
      " total fabric 2+1<2+1=3>>3 bolts fabric\n",
      "\n",
      "Compressed prompt after training\n",
      "A robe takes 2 bolts of blue fiber half that much white fiber. How many bolts in total take?It takes bolt white fiber\n",
      " total amount fabric bolts fabric\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = original_prompts[1]\n",
    "compressed_prompt_before, compressed_prompt_after = compare(prompt)\n",
    "\n",
    "print(\"Original prompt:\")\n",
    "print(prompt)\n",
    "\n",
    "print(\"Compressed prompt before training\")\n",
    "print(compressed_prompt_before)\n",
    "\n",
    "print(\"Compressed prompt after training\")\n",
    "print(compressed_prompt_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| keywords | before training | after tranining |\n",
    "|----------|----------|----------|\n",
    "| 2 bolts blue  | yes  | yes  |\n",
    "| half white | yes  | yes |\n",
    "| 2/2=1 | yes  | no|\n",
    "| 2+1=3 | yes  | no  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2cBhGo_Bp2p",
    "outputId": "a1930e88-14c9-4cb6-eef9-0215c730112c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prompt:\n",
      "Question: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?The cost of the house and repairs came out to 80,000+50,000=$<<80000+50000=130000>>130,000\n",
      "He increased the value of the house by 80,000*1.5=<<80000*1.5=120000>>120,000\n",
      "So the new value of the house is 120,000+80,000=$<<120000+80000=200000>>200,000\n",
      "So he made a profit of 200,000-130,000=$<<200000-130000=70000>>70,000\n",
      "#### 70000\n",
      "Compressed prompt before training\n",
      "Josh house. buys house $80, 000 puts $50, 000 repairs. increased value house 150%. profit cost house repairs 80, 000+50, 000=$<80000+50000=130000>>130, 000\n",
      " increased value house 80, 000*1. 5=<80000*1. 5=120000>>120, 000\n",
      " new value 120, 000+80, 000=$<120000+80000=200000>>200, 000\n",
      " profit 200, 000-130, 000=$<<200000-130000=70000>>70, 000\n",
      "\n",
      "Compressed prompt after training\n",
      ": Josh decides try flipping house. buys house for $80, 000 puts in $50, 000 in repairs. increased value house by 150%. How much profit did make?The cost house and repairs out to 80, 000+50,\n",
      " increased value house by 80, 000*1., 000\n",
      " new value house is 120, 000+80, 000, 000\n",
      " made a profit of 200, 000-130, 000\n",
      " 70000\n"
     ]
    }
   ],
   "source": [
    "prompt = original_prompts[2]\n",
    "compressed_prompt_before, compressed_prompt_after = compare(prompt)\n",
    "\n",
    "print(\"Original prompt:\")\n",
    "print(prompt)\n",
    "\n",
    "print(\"Compressed prompt before training\")\n",
    "print(compressed_prompt_before)\n",
    "\n",
    "print(\"Compressed prompt after training\")\n",
    "print(compressed_prompt_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| keywords | before training | after tranining |\n",
    "|----------|----------|----------|\n",
    "| house 80,000  | yes  | yes  |\n",
    "| $50,000 in repairs | yes  | yes |\n",
    "| increased by 150% | yes  | yes |\n",
    "| 80000+50000=130000 | yes  | no|\n",
    "| 80000*1.5=120000 | yes  | no  |\n",
    "| 120000+80000=200000 | yes  | no |\n",
    "| 200000-130000=70000 | yes  | yes|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ANkn_9DByFs"
   },
   "source": [
    "* This work is to train custom dataset of gsm8k (Q&A of grade school math) following the steps in https://github.com/microsoft/LLMLingua/tree/main/experiments/llmlingua2\n",
    "* From the test results, we can see that LLMLingua2 works well for out-of-domain dataset. Compressed prompts capture most key information such as numbers and operators from the original prompts.\n",
    "* Custom trained model does not improve the compressed prompts, probably due to the limited number (500) of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "055d74565f914469ba00614676e368a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41717bab365d41738ddab51c970ff082",
      "placeholder": "​",
      "style": "IPY_MODEL_47710d0ba8134383a49f8aa69876ec57",
      "value": " 752/752 [00:00&lt;00:00, 66.7kB/s]"
     }
    },
    "0e272568c997469e91a5af53712a94f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15099efd84b8479c9b099eea8eb256ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f6e79ddd93c47f78c8a0c3276c1d8c9",
      "max": 1147,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e272568c997469e91a5af53712a94f6",
      "value": 1147
     }
    },
    "1a6d9af08f574adebcb243051de3989f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6ee8ab8532842e19bbab04922824e1c",
       "IPY_MODEL_37eacec4dbe141668baf92071cba3ccf",
       "IPY_MODEL_055d74565f914469ba00614676e368a3"
      ],
      "layout": "IPY_MODEL_458e208df1794d7ea9820feef97c792e"
     }
    },
    "1c2160b85ff345b9b6e52ca6c2081271": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "242a154053f04d66ba1cee04730f3bb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b0754ec79f54d1f8220eee420187465": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e0615a90da14107bdd9cab3afd165dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_242a154053f04d66ba1cee04730f3bb8",
      "placeholder": "​",
      "style": "IPY_MODEL_3f6f092096744723a243334d80bcd69c",
      "value": " 2.24G/2.24G [00:53&lt;00:00, 41.8MB/s]"
     }
    },
    "3060fa8ab91b4f5ab3f1d7dc8003809e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35849c87372044bda37cfd4a1b33ae87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f185f34678cf437785dafbbf6f85b190",
      "max": 17082756,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b0754ec79f54d1f8220eee420187465",
      "value": 17082756
     }
    },
    "37eacec4dbe141668baf92071cba3ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b71d48e94cb542b7b8a3ddedafb4694e",
      "max": 752,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_902ac47bab3c4b79a1c5c9833ef0771f",
      "value": 752
     }
    },
    "3f6f092096744723a243334d80bcd69c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41717bab365d41738ddab51c970ff082": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4316dbb1ea1646eda58a55ce21d5c62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "441121bfc5d2456baef40918c569e3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1419f06bc834f548ba2363199c1b22a",
      "placeholder": "​",
      "style": "IPY_MODEL_5dbabf2bf8f149f6b6a3f1591367ddae",
      "value": " 1.15k/1.15k [00:00&lt;00:00, 102kB/s]"
     }
    },
    "44124ff62a604f4f8f23f9e3821c4f7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "458e208df1794d7ea9820feef97c792e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47710d0ba8134383a49f8aa69876ec57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f629e730b9948f4ae04bee1f8821bc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b0a05e2a2504acead659b26cd0250df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f58550f941954550b144b26c93ae9681",
       "IPY_MODEL_a318b3606d1f408f9bbd4f99daf139a2",
       "IPY_MODEL_69fde6cac95c4817bd81e5da0797c23c"
      ],
      "layout": "IPY_MODEL_8a3ed035e21b4ab7bf79083f96a7828d"
     }
    },
    "5dbabf2bf8f149f6b6a3f1591367ddae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e48bb2300734ab79a9984a52d3a09ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69fde6cac95c4817bd81e5da0797c23c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aef9cde2bf554d26a3ab281fd9fd1bc1",
      "placeholder": "​",
      "style": "IPY_MODEL_cde386a8fe4942bcb63ea87653b5f604",
      "value": " 280/280 [00:00&lt;00:00, 25.7kB/s]"
     }
    },
    "713f5ec4830b4763839d823c1ffe764b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a0def99c95340c2b398989c77ea904f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bfeed68d5244973a4f6e3b46896bee8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7dea05b331dc40c9a12e18177eec94fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "80ce7bc5c8bd4bc4826755a13bb2c831": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80d09c012dca492195afd4160b8c2f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89611b19571f42aa961262a2f1dfaca3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a3ed035e21b4ab7bf79083f96a7828d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f6e79ddd93c47f78c8a0c3276c1d8c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "902ac47bab3c4b79a1c5c9833ef0771f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99f6755ffba74f7198d0256644b72709": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e9f6963ccd74b04b1c340f38ad0085e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80d09c012dca492195afd4160b8c2f2a",
      "placeholder": "​",
      "style": "IPY_MODEL_adab1fd4ae9a4b3a9eaf926ded6acebb",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "a15cb98c9c7a4b40bc857dc7ad0825c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89611b19571f42aa961262a2f1dfaca3",
      "placeholder": "​",
      "style": "IPY_MODEL_b92c6b101bb341c59a6d9ea1a96015f4",
      "value": "tokenizer.json: 100%"
     }
    },
    "a318b3606d1f408f9bbd4f99daf139a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80ce7bc5c8bd4bc4826755a13bb2c831",
      "max": 280,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7dea05b331dc40c9a12e18177eec94fe",
      "value": 280
     }
    },
    "aa387eb7f3114c65bdf453feb68ba546": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adab1fd4ae9a4b3a9eaf926ded6acebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aef9cde2bf554d26a3ab281fd9fd1bc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b71d48e94cb542b7b8a3ddedafb4694e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b75adac8b42948808db6be7f7f56ed4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99f6755ffba74f7198d0256644b72709",
      "placeholder": "​",
      "style": "IPY_MODEL_7a0def99c95340c2b398989c77ea904f",
      "value": " 17.1M/17.1M [00:00&lt;00:00, 43.3MB/s]"
     }
    },
    "b92c6b101bb341c59a6d9ea1a96015f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c055317a0ffe41a59e3b3cb9740f1b26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e9f6963ccd74b04b1c340f38ad0085e",
       "IPY_MODEL_15099efd84b8479c9b099eea8eb256ca",
       "IPY_MODEL_441121bfc5d2456baef40918c569e3f4"
      ],
      "layout": "IPY_MODEL_44124ff62a604f4f8f23f9e3821c4f7f"
     }
    },
    "ca3a9ab75e594f98be5770239fc6a333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f629e730b9948f4ae04bee1f8821bc3",
      "placeholder": "​",
      "style": "IPY_MODEL_713f5ec4830b4763839d823c1ffe764b",
      "value": "model.safetensors: 100%"
     }
    },
    "cde386a8fe4942bcb63ea87653b5f604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1419f06bc834f548ba2363199c1b22a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1542c26406746e88104bb2d9ca64036": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d534147c6a4943c2a9f40576d317dc5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca3a9ab75e594f98be5770239fc6a333",
       "IPY_MODEL_e35cc3c94e8f4db4b12b10b49389a49d",
       "IPY_MODEL_2e0615a90da14107bdd9cab3afd165dd"
      ],
      "layout": "IPY_MODEL_d1542c26406746e88104bb2d9ca64036"
     }
    },
    "d6ee8ab8532842e19bbab04922824e1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa387eb7f3114c65bdf453feb68ba546",
      "placeholder": "​",
      "style": "IPY_MODEL_4316dbb1ea1646eda58a55ce21d5c62d",
      "value": "config.json: 100%"
     }
    },
    "e35cc3c94e8f4db4b12b10b49389a49d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c2160b85ff345b9b6e52ca6c2081271",
      "max": 2235829648,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e74d2db6b99746ef81a2b821d5b18d7c",
      "value": 2235829648
     }
    },
    "e74d2db6b99746ef81a2b821d5b18d7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef58dc5e3b8e46b588e97de224efb6bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a15cb98c9c7a4b40bc857dc7ad0825c3",
       "IPY_MODEL_35849c87372044bda37cfd4a1b33ae87",
       "IPY_MODEL_b75adac8b42948808db6be7f7f56ed4d"
      ],
      "layout": "IPY_MODEL_3060fa8ab91b4f5ab3f1d7dc8003809e"
     }
    },
    "f185f34678cf437785dafbbf6f85b190": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f58550f941954550b144b26c93ae9681": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e48bb2300734ab79a9984a52d3a09ab",
      "placeholder": "​",
      "style": "IPY_MODEL_7bfeed68d5244973a4f6e3b46896bee8",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
